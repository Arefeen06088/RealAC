{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b71e42b6-d1f2-4a31-8c3c-eba8adc60656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "658/658 [==============================] - 0s 497us/step\n",
      "74/74 [==============================] - 0s 490us/step\n",
      "Train accuracy: 0.8281042023198326\n",
      "Test accuracy: 0.8284858853721129\n",
      "658/658 [==============================] - 0s 465us/step\n",
      "74/74 [==============================] - 0s 486us/step\n",
      "Train accuracy: 0.8281042023198326\n",
      "Test accuracy: 0.8284858853721129\n",
      "658/658 [==============================] - 0s 459us/step\n",
      "Epoch 1/80\n",
      "1171/1184 [============================>.] - ETA: 0s - loss: 49298500.9641 - reconstruction_loss: 47418764.0000 - kl_loss: 9.8701 - classification_loss: 77.4940 - mi_loss: 0.3629Epoch 1: CF Preservation Rate = 1.0000\n",
      "1184/1184 [==============================] - 11s 5ms/step - loss: 49278156.1325 - reconstruction_loss: 47594864.0000 - kl_loss: 9.9555 - classification_loss: 76.7260 - mi_loss: 0.3622 - val_loss: 1.8054 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_classification_loss: 0.0000e+00 - val_mi_loss: 0.0000e+00\n",
      "Epoch 2/80\n",
      "1176/1184 [============================>.] - ETA: 0s - loss: 46569592.0000 - reconstruction_loss: 46568816.0000 - kl_loss: 20.1865 - classification_loss: 3.9847 - mi_loss: 0.3477Epoch 2: CF Preservation Rate = 1.0000\n",
      "1184/1184 [==============================] - 3s 3ms/step - loss: 46527332.0000 - reconstruction_loss: 46954944.0000 - kl_loss: 20.2053 - classification_loss: 3.9749 - mi_loss: 0.3475 - val_loss: 2.1660 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_classification_loss: 0.0000e+00 - val_mi_loss: 0.0000e+00\n",
      "Epoch 3/80\n",
      "1177/1184 [============================>.] - ETA: 0s - loss: 44918584.0000 - reconstruction_loss: 44917956.0000 - kl_loss: 23.8782 - classification_loss: 3.1830 - mi_loss: 0.3894Epoch 3: CF Preservation Rate = 1.0000\n",
      "1184/1184 [==============================] - 3s 2ms/step - loss: 44688724.0000 - reconstruction_loss: 44663552.0000 - kl_loss: 23.8786 - classification_loss: 3.1776 - mi_loss: 0.3899 - val_loss: 2.9174 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_classification_loss: 0.0000e+00 - val_mi_loss: 0.0000e+00\n",
      "Epoch 4/80\n",
      "1163/1184 [============================>.] - ETA: 0s - loss: 41931496.0000 - reconstruction_loss: 41930548.0000 - kl_loss: 22.4532 - classification_loss: 4.8815 - mi_loss: 0.4967Epoch 4: CF Preservation Rate = 1.0000\n",
      "1184/1184 [==============================] - 3s 3ms/step - loss: 42572240.0000 - reconstruction_loss: 42546676.0000 - kl_loss: 22.4242 - classification_loss: 4.9746 - mi_loss: 0.4975 - val_loss: 3.6726 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_classification_loss: 0.0000e+00 - val_mi_loss: 0.0000e+00\n",
      "Epoch 5/80\n",
      "1157/1184 [============================>.] - ETA: 0s - loss: 40594228.0000 - reconstruction_loss: 40592332.0000 - kl_loss: 21.7934 - classification_loss: 9.6470 - mi_loss: 0.5701Epoch 5: CF Preservation Rate = 1.0000\n",
      "1184/1184 [==============================] - 3s 3ms/step - loss: 40275444.0000 - reconstruction_loss: 40255756.0000 - kl_loss: 21.8041 - classification_loss: 9.6956 - mi_loss: 0.5718 - val_loss: 3.0116 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_classification_loss: 0.0000e+00 - val_mi_loss: 0.0000e+00\n",
      "Epoch 6/80\n",
      "1174/1184 [============================>.] - ETA: 0s - loss: 37876336.0000 - reconstruction_loss: 37874468.0000 - kl_loss: 23.3980 - classification_loss: 9.3257 - mi_loss: 0.6281Epoch 6: CF Preservation Rate = 1.0000\n",
      "1184/1184 [==============================] - 3s 2ms/step - loss: 38458832.0000 - reconstruction_loss: 38435008.0000 - kl_loss: 23.3932 - classification_loss: 9.4064 - mi_loss: 0.6282 - val_loss: 3.1715 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_classification_loss: 0.0000e+00 - val_mi_loss: 0.0000e+00\n",
      "Epoch 7/80\n",
      "1176/1184 [============================>.] - ETA: 0s - loss: 36747248.0000 - reconstruction_loss: 36744988.0000 - kl_loss: 23.9318 - classification_loss: 11.3751 - mi_loss: 0.6267Epoch 7: CF Preservation Rate = 1.0000\n",
      "1184/1184 [==============================] - 3s 2ms/step - loss: 37050168.0000 - reconstruction_loss: 37030644.0000 - kl_loss: 23.9311 - classification_loss: 11.3806 - mi_loss: 0.6263 - val_loss: 2.9416 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_classification_loss: 0.0000e+00 - val_mi_loss: 0.0000e+00\n",
      "Epoch 8/80\n",
      "1183/1184 [============================>.] - ETA: 0s - loss: 35966532.0000 - reconstruction_loss: 35964200.0000 - kl_loss: 23.2090 - classification_loss: 11.9254 - mi_loss: 0.6006Epoch 8: CF Preservation Rate = 1.0000\n",
      "1184/1184 [==============================] - 2s 2ms/step - loss: 35957168.0000 - reconstruction_loss: 35934256.0000 - kl_loss: 23.2066 - classification_loss: 11.9306 - mi_loss: 0.6005 - val_loss: 3.4730 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_classification_loss: 0.0000e+00 - val_mi_loss: 0.0000e+00\n",
      "Epoch 9/80\n",
      "1172/1184 [============================>.] - ETA: 0s - loss: 34844848.0000 - reconstruction_loss: 34842224.0000 - kl_loss: 22.7609 - classification_loss: 13.0563 - mi_loss: 0.5599Epoch 9: CF Preservation Rate = 1.0000\n",
      "1184/1184 [==============================] - 3s 3ms/step - loss: 35021484.0000 - reconstruction_loss: 34998844.0000 - kl_loss: 22.7636 - classification_loss: 13.0544 - mi_loss: 0.5596 - val_loss: 3.3461 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_classification_loss: 0.0000e+00 - val_mi_loss: 0.0000e+00\n",
      "Epoch 10/80\n",
      "1167/1184 [============================>.] - ETA: 0s - loss: 34240004.0000 - reconstruction_loss: 34237484.0000 - kl_loss: 22.9712 - classification_loss: 12.4978 - mi_loss: 0.5196Epoch 10: CF Preservation Rate = 1.0000\n",
      "1184/1184 [==============================] - 3s 3ms/step - loss: 34258056.0000 - reconstruction_loss: 34235976.0000 - kl_loss: 22.9692 - classification_loss: 12.5098 - mi_loss: 0.5198 - val_loss: 3.0769 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_classification_loss: 0.0000e+00 - val_mi_loss: 0.0000e+00\n",
      "Epoch 11/80\n",
      "1171/1184 [============================>.] - ETA: 0s - loss: 33297686.0000 - reconstruction_loss: 33295548.0000 - kl_loss: 23.1862 - classification_loss: 10.7747 - mi_loss: 0.5212Epoch 11: CF Preservation Rate = 1.0000\n",
      "1184/1184 [==============================] - 3s 3ms/step - loss: 33428234.0000 - reconstruction_loss: 33408948.0000 - kl_loss: 23.1807 - classification_loss: 10.7523 - mi_loss: 0.5215 - val_loss: 2.9193 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_classification_loss: 0.0000e+00 - val_mi_loss: 0.0000e+00\n",
      "Epoch 12/80\n",
      "1176/1184 [============================>.] - ETA: 0s - loss: 32825470.0000 - reconstruction_loss: 32823474.0000 - kl_loss: 23.2799 - classification_loss: 10.1454 - mi_loss: 0.5011Epoch 12: CF Preservation Rate = 1.0000\n",
      "1184/1184 [==============================] - 3s 2ms/step - loss: 32624692.0000 - reconstruction_loss: 32604080.0000 - kl_loss: 23.2766 - classification_loss: 10.1565 - mi_loss: 0.5014 - val_loss: 2.9752 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_classification_loss: 0.0000e+00 - val_mi_loss: 0.0000e+00\n",
      "Epoch 13/80\n",
      "1168/1184 [============================>.] - ETA: 0s - loss: 32144836.0000 - reconstruction_loss: 32142676.0000 - kl_loss: 23.0665 - classification_loss: 10.8586 - mi_loss: 0.5109Epoch 13: CF Preservation Rate = 1.0000\n",
      "1184/1184 [==============================] - 3s 3ms/step - loss: 32050080.0000 - reconstruction_loss: 32029606.0000 - kl_loss: 23.0646 - classification_loss: 10.7991 - mi_loss: 0.5106 - val_loss: 2.8826 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_classification_loss: 0.0000e+00 - val_mi_loss: 0.0000e+00\n",
      "Epoch 14/80\n",
      "1178/1184 [============================>.] - ETA: 0s - loss: 31677744.0000 - reconstruction_loss: 31675620.0000 - kl_loss: 23.2125 - classification_loss: 10.7302 - mi_loss: 0.5064Epoch 14: CF Preservation Rate = 1.0000\n",
      "1184/1184 [==============================] - 3s 3ms/step - loss: 31684750.0000 - reconstruction_loss: 31665906.0000 - kl_loss: 23.2123 - classification_loss: 10.7223 - mi_loss: 0.5066 - val_loss: 2.9752 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_classification_loss: 0.0000e+00 - val_mi_loss: 0.0000e+00\n",
      "Epoch 15/80\n",
      "1176/1184 [============================>.] - ETA: 0s - loss: 31281984.0000 - reconstruction_loss: 31279804.0000 - kl_loss: 23.3279 - classification_loss: 10.8114 - mi_loss: 0.5050Epoch 15: CF Preservation Rate = 1.0000\n",
      "1184/1184 [==============================] - 3s 3ms/step - loss: 31242004.0000 - reconstruction_loss: 31222010.0000 - kl_loss: 23.3292 - classification_loss: 10.8360 - mi_loss: 0.5054 - val_loss: 3.2190 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_classification_loss: 0.0000e+00 - val_mi_loss: 0.0000e+00\n",
      "Epoch 16/80\n",
      "1181/1184 [============================>.] - ETA: 0s - loss: 30907154.0000 - reconstruction_loss: 30904854.0000 - kl_loss: 23.0488 - classification_loss: 11.5032 - mi_loss: 0.5081Epoch 16: CF Preservation Rate = 1.0000\n",
      "1184/1184 [==============================] - 3s 3ms/step - loss: 30846926.0000 - reconstruction_loss: 30826904.0000 - kl_loss: 23.0476 - classification_loss: 11.4954 - mi_loss: 0.5080 - val_loss: 2.7441 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_classification_loss: 0.0000e+00 - val_mi_loss: 0.0000e+00\n",
      "Epoch 17/80\n",
      "1167/1184 [============================>.] - ETA: 0s - loss: 30283490.0000 - reconstruction_loss: 30281220.0000 - kl_loss: 22.4465 - classification_loss: 11.3315 - mi_loss: 0.5062Epoch 17: CF Preservation Rate = 1.0000\n",
      "1184/1184 [==============================] - 3s 3ms/step - loss: 30458698.0000 - reconstruction_loss: 30439058.0000 - kl_loss: 22.4426 - classification_loss: 11.3189 - mi_loss: 0.5062 - val_loss: 2.8746 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_classification_loss: 0.0000e+00 - val_mi_loss: 0.0000e+00\n",
      "Epoch 18/80\n",
      "1177/1184 [============================>.] - ETA: 0s - loss: 30398980.0000 - reconstruction_loss: 30396744.0000 - kl_loss: 22.4976 - classification_loss: 11.2694 - mi_loss: 0.5213Epoch 18: CF Preservation Rate = 1.0000\n",
      "1184/1184 [==============================] - 3s 2ms/step - loss: 30237600.0000 - reconstruction_loss: 30218016.0000 - kl_loss: 22.4968 - classification_loss: 11.2849 - mi_loss: 0.5213 - val_loss: 2.8729 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_classification_loss: 0.0000e+00 - val_mi_loss: 0.0000e+00\n",
      "Epoch 19/80\n",
      "1181/1184 [============================>.] - ETA: 0s - loss: 30009818.0000 - reconstruction_loss: 30007514.0000 - kl_loss: 22.9371 - classification_loss: 11.6365 - mi_loss: 0.5293Epoch 19: CF Preservation Rate = 1.0000\n",
      "1184/1184 [==============================] - 3s 3ms/step - loss: 29957426.0000 - reconstruction_loss: 29937826.0000 - kl_loss: 22.9365 - classification_loss: 11.6180 - mi_loss: 0.5290 - val_loss: 2.8407 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_classification_loss: 0.0000e+00 - val_mi_loss: 0.0000e+00\n",
      "Epoch 20/80\n",
      "1171/1184 [============================>.] - ETA: 0s - loss: 29298314.0000 - reconstruction_loss: 29296068.0000 - kl_loss: 23.5066 - classification_loss: 11.2781 - mi_loss: 0.5501Epoch 20: CF Preservation Rate = 1.0000\n",
      "1184/1184 [==============================] - 3s 3ms/step - loss: 29730426.0000 - reconstruction_loss: 30094596.0000 - kl_loss: 23.5027 - classification_loss: 11.2172 - mi_loss: 0.5503 - val_loss: 2.8940 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_classification_loss: 0.0000e+00 - val_mi_loss: 0.0000e+00\n",
      "Epoch 21/80\n",
      "1183/1184 [============================>.] - ETA: 0s - loss: 28829088.0000 - reconstruction_loss: 28826958.0000 - kl_loss: 24.0991 - classification_loss: 10.6328 - mi_loss: 0.5500Epoch 21: CF Preservation Rate = 1.0000\n",
      "1184/1184 [==============================] - 3s 3ms/step - loss: 28821872.0000 - reconstruction_loss: 28803884.0000 - kl_loss: 24.0989 - classification_loss: 10.6310 - mi_loss: 0.5499 - val_loss: 3.0625 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_classification_loss: 0.0000e+00 - val_mi_loss: 0.0000e+00\n",
      "Epoch 22/80\n",
      "1183/1184 [============================>.] - ETA: 0s - loss: 28560546.0000 - reconstruction_loss: 28558714.0000 - kl_loss: 24.7204 - classification_loss: 9.2031 - mi_loss: 0.5548Epoch 22: CF Preservation Rate = 1.0000\n",
      "1184/1184 [==============================] - 3s 3ms/step - loss: 28553954.0000 - reconstruction_loss: 28537632.0000 - kl_loss: 24.7215 - classification_loss: 9.2062 - mi_loss: 0.5547 - val_loss: 3.0336 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_classification_loss: 0.0000e+00 - val_mi_loss: 0.0000e+00\n",
      "Epoch 23/80\n",
      "1165/1184 [============================>.] - ETA: 0s - loss: 28583800.0000 - reconstruction_loss: 28581800.0000 - kl_loss: 24.9335 - classification_loss: 10.0134 - mi_loss: 0.5738Epoch 23: CF Preservation Rate = 1.0000\n",
      "1184/1184 [==============================] - 3s 3ms/step - loss: 28546700.0000 - reconstruction_loss: 28528204.0000 - kl_loss: 24.9351 - classification_loss: 10.0223 - mi_loss: 0.5739 - val_loss: 2.9801 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_classification_loss: 0.0000e+00 - val_mi_loss: 0.0000e+00\n",
      "Epoch 24/80\n",
      "1171/1184 [============================>.] - ETA: 0s - loss: 27740112.0000 - reconstruction_loss: 27738254.0000 - kl_loss: 24.5946 - classification_loss: 9.1709 - mi_loss: 0.5695Epoch 24: CF Preservation Rate = 1.0000\n",
      "1184/1184 [==============================] - 3s 3ms/step - loss: 28034936.0000 - reconstruction_loss: 28018112.0000 - kl_loss: 24.5962 - classification_loss: 9.1692 - mi_loss: 0.5693 - val_loss: 2.9267 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_classification_loss: 0.0000e+00 - val_mi_loss: 0.0000e+00\n",
      "Epoch 25/80\n",
      "1170/1184 [============================>.] - ETA: 0s - loss: 27206614.0000 - reconstruction_loss: 27205040.0000 - kl_loss: 24.7430 - classification_loss: 7.8040 - mi_loss: 0.5683Epoch 25: CF Preservation Rate = 1.0000\n",
      "1184/1184 [==============================] - 3s 2ms/step - loss: 27557514.0000 - reconstruction_loss: 27540006.0000 - kl_loss: 24.7401 - classification_loss: 7.7705 - mi_loss: 0.5679 - val_loss: 2.7253 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_classification_loss: 0.0000e+00 - val_mi_loss: 0.0000e+00\n",
      "Epoch 26/80\n",
      "1169/1184 [============================>.] - ETA: 0s - loss: 27636184.0000 - reconstruction_loss: 27634666.0000 - kl_loss: 24.7360 - classification_loss: 7.5925 - mi_loss: 0.5630Epoch 26: CF Preservation Rate = 1.0000\n",
      "1184/1184 [==============================] - 3s 2ms/step - loss: 27554698.0000 - reconstruction_loss: 27537196.0000 - kl_loss: 24.7344 - classification_loss: 7.5965 - mi_loss: 0.5632 - val_loss: 2.4593 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_classification_loss: 0.0000e+00 - val_mi_loss: 0.0000e+00\n",
      "Epoch 27/80\n",
      "1168/1184 [============================>.] - ETA: 0s - loss: 26674770.0000 - reconstruction_loss: 26673440.0000 - kl_loss: 25.0880 - classification_loss: 6.7481 - mi_loss: 0.5468Epoch 27: CF Preservation Rate = 1.0000\n",
      "1184/1184 [==============================] - 3s 3ms/step - loss: 26707934.0000 - reconstruction_loss: 26691152.0000 - kl_loss: 25.0896 - classification_loss: 6.7318 - mi_loss: 0.5462 - val_loss: 2.3070 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_classification_loss: 0.0000e+00 - val_mi_loss: 0.0000e+00\n",
      "Epoch 28/80\n",
      "1178/1184 [============================>.] - ETA: 0s - loss: 26068192.0000 - reconstruction_loss: 26066858.0000 - kl_loss: 25.5948 - classification_loss: 6.5559 - mi_loss: 0.5384Epoch 28: CF Preservation Rate = 1.0000\n",
      "1184/1184 [==============================] - 3s 2ms/step - loss: 26246144.0000 - reconstruction_loss: 26229620.0000 - kl_loss: 25.5971 - classification_loss: 6.5511 - mi_loss: 0.5382 - val_loss: 2.8491 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_classification_loss: 0.0000e+00 - val_mi_loss: 0.0000e+00\n",
      "Epoch 29/80\n",
      "1160/1184 [============================>.] - ETA: 0s - loss: 26335738.0000 - reconstruction_loss: 26334428.0000 - kl_loss: 25.5090 - classification_loss: 6.5680 - mi_loss: 0.5319Epoch 29: CF Preservation Rate = 1.0000\n",
      "1184/1184 [==============================] - 3s 3ms/step - loss: 26190128.0000 - reconstruction_loss: 26173676.0000 - kl_loss: 25.5020 - classification_loss: 6.5058 - mi_loss: 0.5317 - val_loss: 2.6396 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_classification_loss: 0.0000e+00 - val_mi_loss: 0.0000e+00\n",
      "Epoch 30/80\n",
      "1178/1184 [============================>.] - ETA: 0s - loss: 25911478.0000 - reconstruction_loss: 25910280.0000 - kl_loss: 25.5922 - classification_loss: 5.9935 - mi_loss: 0.5220Epoch 30: CF Preservation Rate = 1.0000\n",
      "1184/1184 [==============================] - 3s 2ms/step - loss: 25918748.0000 - reconstruction_loss: 25903976.0000 - kl_loss: 25.5907 - classification_loss: 5.9815 - mi_loss: 0.5219 - val_loss: 2.9001 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_classification_loss: 0.0000e+00 - val_mi_loss: 0.0000e+00\n",
      "Epoch 31/80\n",
      "1165/1184 [============================>.] - ETA: 0s - loss: 25405288.0000 - reconstruction_loss: 25404172.0000 - kl_loss: 25.6087 - classification_loss: 5.6074 - mi_loss: 0.5185Epoch 31: CF Preservation Rate = 1.0000\n",
      "1184/1184 [==============================] - 3s 3ms/step - loss: 25130774.0000 - reconstruction_loss: 25116378.0000 - kl_loss: 25.6159 - classification_loss: 5.5896 - mi_loss: 0.5184 - val_loss: 2.6018 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_classification_loss: 0.0000e+00 - val_mi_loss: 0.0000e+00\n",
      "Epoch 32/80\n",
      "1167/1184 [============================>.] - ETA: 0s - loss: 25257000.0000 - reconstruction_loss: 25255978.0000 - kl_loss: 25.9415 - classification_loss: 4.9690 - mi_loss: 0.5084Epoch 32: CF Preservation Rate = 1.0000\n",
      "1184/1184 [==============================] - 3s 3ms/step - loss: 24910372.0000 - reconstruction_loss: 24894918.0000 - kl_loss: 25.9581 - classification_loss: 4.9927 - mi_loss: 0.5089 - val_loss: 2.7226 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_classification_loss: 0.0000e+00 - val_mi_loss: 0.0000e+00\n",
      "Epoch 33/80\n",
      "1178/1184 [============================>.] - ETA: 0s - loss: 24532476.0000 - reconstruction_loss: 24531430.0000 - kl_loss: 26.0288 - classification_loss: 5.2990 - mi_loss: 0.5013Epoch 33: CF Preservation Rate = 1.0000\n",
      "1184/1184 [==============================] - 3s 3ms/step - loss: 24422432.0000 - reconstruction_loss: 24407200.0000 - kl_loss: 26.0330 - classification_loss: 5.3252 - mi_loss: 0.5016 - val_loss: 2.6744 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_classification_loss: 0.0000e+00 - val_mi_loss: 0.0000e+00\n",
      "Epoch 34/80\n",
      "1168/1184 [============================>.] - ETA: 0s - loss: 24006438.0000 - reconstruction_loss: 24005380.0000 - kl_loss: 26.8736 - classification_loss: 5.2109 - mi_loss: 0.5096Epoch 34: CF Preservation Rate = 1.0000\n",
      "1184/1184 [==============================] - 3s 3ms/step - loss: 23925938.0000 - reconstruction_loss: 23911034.0000 - kl_loss: 26.8818 - classification_loss: 5.1968 - mi_loss: 0.5096 - val_loss: 2.7060 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_classification_loss: 0.0000e+00 - val_mi_loss: 0.0000e+00\n",
      "Epoch 35/80\n",
      "1157/1184 [============================>.] - ETA: 0s - loss: 23551514.0000 - reconstruction_loss: 23550594.0000 - kl_loss: 26.9470 - classification_loss: 4.3351 - mi_loss: 0.5086Epoch 35: CF Preservation Rate = 1.0000\n",
      "1184/1184 [==============================] - 2s 2ms/step - loss: 23948886.0000 - reconstruction_loss: 23935138.0000 - kl_loss: 26.9272 - classification_loss: 4.3238 - mi_loss: 0.5073 - val_loss: 2.4369 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_classification_loss: 0.0000e+00 - val_mi_loss: 0.0000e+00\n",
      "Epoch 36/80\n",
      "1177/1184 [============================>.] - ETA: 0s - loss: 23391400.0000 - reconstruction_loss: 23390538.0000 - kl_loss: 26.4325 - classification_loss: 4.3361 - mi_loss: 0.5111Epoch 36: CF Preservation Rate = 1.0000\n",
      "1184/1184 [==============================] - 3s 2ms/step - loss: 23266714.0000 - reconstruction_loss: 23252370.0000 - kl_loss: 26.4399 - classification_loss: 4.3442 - mi_loss: 0.5113 - val_loss: 3.1611 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_classification_loss: 0.0000e+00 - val_mi_loss: 0.0000e+00\n",
      "Epoch 37/80\n",
      "1164/1184 [============================>.] - ETA: 0s - loss: 22623388.0000 - reconstruction_loss: 22622490.0000 - kl_loss: 26.1100 - classification_loss: 4.5378 - mi_loss: 0.5182Epoch 37: CF Preservation Rate = 1.0000\n",
      "1184/1184 [==============================] - 3s 3ms/step - loss: 22679070.0000 - reconstruction_loss: 22665126.0000 - kl_loss: 26.1179 - classification_loss: 4.5433 - mi_loss: 0.5182 - val_loss: 2.9887 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_classification_loss: 0.0000e+00 - val_mi_loss: 0.0000e+00\n",
      "Epoch 38/80\n",
      "1161/1184 [============================>.] - ETA: 0s - loss: 22631262.0000 - reconstruction_loss: 22630412.0000 - kl_loss: 26.0899 - classification_loss: 4.3404 - mi_loss: 0.5293Epoch 38: CF Preservation Rate = 1.0000\n",
      "1184/1184 [==============================] - 3s 3ms/step - loss: 22410400.0000 - reconstruction_loss: 22396562.0000 - kl_loss: 26.1024 - classification_loss: 4.3840 - mi_loss: 0.5294 - val_loss: 2.7068 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_classification_loss: 0.0000e+00 - val_mi_loss: 0.0000e+00\n",
      "Epoch 39/80\n",
      "1165/1184 [============================>.] - ETA: 0s - loss: 22247040.0000 - reconstruction_loss: 22246150.0000 - kl_loss: 26.1869 - classification_loss: 4.3762 - mi_loss: 0.5318Epoch 39: CF Preservation Rate = 1.0000\n",
      "1184/1184 [==============================] - 3s 3ms/step - loss: 22015838.0000 - reconstruction_loss: 22002200.0000 - kl_loss: 26.1883 - classification_loss: 4.3591 - mi_loss: 0.5320 - val_loss: 2.8512 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_classification_loss: 0.0000e+00 - val_mi_loss: 0.0000e+00\n",
      "Epoch 40/80\n",
      "1180/1184 [============================>.] - ETA: 0s - loss: 21485618.0000 - reconstruction_loss: 21484724.0000 - kl_loss: 25.3510 - classification_loss: 4.4361 - mi_loss: 0.5361Epoch 40: CF Preservation Rate = 1.0000\n",
      "1184/1184 [==============================] - 3s 3ms/step - loss: 21425690.0000 - reconstruction_loss: 21412374.0000 - kl_loss: 25.3553 - classification_loss: 4.4303 - mi_loss: 0.5360 - val_loss: 2.8945 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_classification_loss: 0.0000e+00 - val_mi_loss: 0.0000e+00\n",
      "Epoch 41/80\n",
      "1183/1184 [============================>.] - ETA: 0s - loss: 21005294.0000 - reconstruction_loss: 21004322.0000 - kl_loss: 25.6727 - classification_loss: 4.8983 - mi_loss: 0.5249Epoch 41: CF Preservation Rate = 1.0000\n",
      "1184/1184 [==============================] - 3s 3ms/step - loss: 20999756.0000 - reconstruction_loss: 20986612.0000 - kl_loss: 25.6766 - classification_loss: 4.8981 - mi_loss: 0.5248 - val_loss: 2.8670 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_classification_loss: 0.0000e+00 - val_mi_loss: 0.0000e+00\n",
      "Epoch 42/80\n",
      "1163/1184 [============================>.] - ETA: 0s - loss: 20199840.0000 - reconstruction_loss: 20198964.0000 - kl_loss: 26.5974 - classification_loss: 4.3566 - mi_loss: 0.5177Epoch 42: CF Preservation Rate = 1.0000\n",
      "1184/1184 [==============================] - 3s 2ms/step - loss: 20431040.0000 - reconstruction_loss: 20418356.0000 - kl_loss: 26.5836 - classification_loss: 4.3768 - mi_loss: 0.5167 - val_loss: 2.6987 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_classification_loss: 0.0000e+00 - val_mi_loss: 0.0000e+00\n",
      "Epoch 43/80\n",
      "1176/1184 [============================>.] - ETA: 0s - loss: 19960532.0000 - reconstruction_loss: 19959670.0000 - kl_loss: 26.6435 - classification_loss: 4.2131 - mi_loss: 0.5099Epoch 43: CF Preservation Rate = 1.0000\n",
      "1184/1184 [==============================] - 3s 3ms/step - loss: 20024670.0000 - reconstruction_loss: 20012212.0000 - kl_loss: 26.6498 - classification_loss: 4.1978 - mi_loss: 0.5097 - val_loss: 2.8351 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_classification_loss: 0.0000e+00 - val_mi_loss: 0.0000e+00\n",
      "Epoch 44/80\n",
      "1169/1184 [============================>.] - ETA: 0s - loss: 19881998.0000 - reconstruction_loss: 19881078.0000 - kl_loss: 26.5176 - classification_loss: 4.5972 - mi_loss: 0.5192Epoch 44: CF Preservation Rate = 1.0000\n",
      "1184/1184 [==============================] - 3s 2ms/step - loss: 19914926.0000 - reconstruction_loss: 19904818.0000 - kl_loss: 26.5142 - classification_loss: 4.5726 - mi_loss: 0.5191 - val_loss: 2.5781 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_classification_loss: 0.0000e+00 - val_mi_loss: 0.0000e+00\n",
      "Epoch 45/80\n",
      "1176/1184 [============================>.] - ETA: 0s - loss: 19011590.0000 - reconstruction_loss: 19010746.0000 - kl_loss: 26.2796 - classification_loss: 4.2498 - mi_loss: 0.5192Epoch 45: CF Preservation Rate = 1.0000\n",
      "1184/1184 [==============================] - 3s 3ms/step - loss: 18895598.0000 - reconstruction_loss: 18884136.0000 - kl_loss: 26.2778 - classification_loss: 4.2565 - mi_loss: 0.5195 - val_loss: 2.6708 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_classification_loss: 0.0000e+00 - val_mi_loss: 0.0000e+00\n",
      "Epoch 46/80\n",
      "1172/1184 [============================>.] - ETA: 0s - loss: 18381756.0000 - reconstruction_loss: 18380730.0000 - kl_loss: 26.0533 - classification_loss: 5.1546 - mi_loss: 0.5358Epoch 46: CF Preservation Rate = 1.0000\n",
      "1184/1184 [==============================] - 3s 2ms/step - loss: 18377532.0000 - reconstruction_loss: 18365974.0000 - kl_loss: 26.0595 - classification_loss: 5.2104 - mi_loss: 0.5355 - val_loss: 3.1442 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_classification_loss: 0.0000e+00 - val_mi_loss: 0.0000e+00\n",
      "Epoch 47/80\n",
      "1177/1184 [============================>.] - ETA: 0s - loss: 17934022.0000 - reconstruction_loss: 17932944.0000 - kl_loss: 26.2580 - classification_loss: 5.4646 - mi_loss: 0.5376Epoch 47: CF Preservation Rate = 1.0000\n",
      "1184/1184 [==============================] - 3s 3ms/step - loss: 18156724.0000 - reconstruction_loss: 18145120.0000 - kl_loss: 26.2646 - classification_loss: 5.4486 - mi_loss: 0.5374 - val_loss: 3.4895 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_classification_loss: 0.0000e+00 - val_mi_loss: 0.0000e+00\n",
      "Epoch 48/80\n",
      "1169/1184 [============================>.] - ETA: 0s - loss: 18048132.0000 - reconstruction_loss: 18047250.0000 - kl_loss: 26.8699 - classification_loss: 4.4676 - mi_loss: 0.5371Epoch 48: CF Preservation Rate = 1.0000\n",
      "1184/1184 [==============================] - 3s 3ms/step - loss: 18087900.0000 - reconstruction_loss: 18078386.0000 - kl_loss: 26.8587 - classification_loss: 4.4409 - mi_loss: 0.5370 - val_loss: 3.0742 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_classification_loss: 0.0000e+00 - val_mi_loss: 0.0000e+00\n",
      "Epoch 49/80\n",
      "1167/1184 [============================>.] - ETA: 0s - loss: 17719542.0000 - reconstruction_loss: 17718706.0000 - kl_loss: 26.5205 - classification_loss: 4.0922 - mi_loss: 0.5236Epoch 49: CF Preservation Rate = 1.0000\n",
      "1184/1184 [==============================] - 3s 3ms/step - loss: 17628450.0000 - reconstruction_loss: 17617388.0000 - kl_loss: 26.5313 - classification_loss: 4.0805 - mi_loss: 0.5235 - val_loss: 3.0939 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_classification_loss: 0.0000e+00 - val_mi_loss: 0.0000e+00\n",
      "Epoch 50/80\n",
      "1179/1184 [============================>.] - ETA: 0s - loss: 17341420.0000 - reconstruction_loss: 17340478.0000 - kl_loss: 26.6203 - classification_loss: 4.5994 - mi_loss: 0.5295Epoch 50: CF Preservation Rate = 1.0000\n",
      "1184/1184 [==============================] - 3s 2ms/step - loss: 17278802.0000 - reconstruction_loss: 17268742.0000 - kl_loss: 26.6198 - classification_loss: 4.5893 - mi_loss: 0.5296 - val_loss: 2.9411 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_classification_loss: 0.0000e+00 - val_mi_loss: 0.0000e+00\n",
      "Epoch 51/80\n",
      "1174/1184 [============================>.] - ETA: 0s - loss: 16788880.0000 - reconstruction_loss: 16788070.0000 - kl_loss: 26.5307 - classification_loss: 4.0763 - mi_loss: 0.5309Epoch 51: CF Preservation Rate = 1.0000\n",
      "1184/1184 [==============================] - 3s 3ms/step - loss: 16804376.0000 - reconstruction_loss: 16793850.0000 - kl_loss: 26.5322 - classification_loss: 4.0806 - mi_loss: 0.5305 - val_loss: 2.8063 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_classification_loss: 0.0000e+00 - val_mi_loss: 0.0000e+00\n",
      "Epoch 52/80\n",
      "1160/1184 [============================>.] - ETA: 0s - loss: 15314753.0000 - reconstruction_loss: 15313913.0000 - kl_loss: 26.7069 - classification_loss: 4.1921 - mi_loss: 0.5228Epoch 52: CF Preservation Rate = 1.0000\n",
      "1184/1184 [==============================] - 3s 2ms/step - loss: 15515574.0000 - reconstruction_loss: 15506026.0000 - kl_loss: 26.7010 - classification_loss: 4.2184 - mi_loss: 0.5219 - val_loss: 2.7892 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_classification_loss: 0.0000e+00 - val_mi_loss: 0.0000e+00\n",
      "Epoch 53/80\n",
      "1170/1184 [============================>.] - ETA: 0s - loss: 15603877.0000 - reconstruction_loss: 15603068.0000 - kl_loss: 26.2559 - classification_loss: 4.0636 - mi_loss: 0.5281Epoch 53: CF Preservation Rate = 1.0000\n",
      "1184/1184 [==============================] - 3s 2ms/step - loss: 15429266.0000 - reconstruction_loss: 15419508.0000 - kl_loss: 26.2677 - classification_loss: 4.0798 - mi_loss: 0.5286 - val_loss: 2.5384 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_classification_loss: 0.0000e+00 - val_mi_loss: 0.0000e+00\n",
      "Epoch 54/80\n",
      "1166/1184 [============================>.] - ETA: 0s - loss: 15163169.0000 - reconstruction_loss: 15162319.0000 - kl_loss: 26.1169 - classification_loss: 4.2265 - mi_loss: 0.5253Epoch 54: CF Preservation Rate = 1.0000\n",
      "1184/1184 [==============================] - 3s 3ms/step - loss: 15008156.0000 - reconstruction_loss: 14998666.0000 - kl_loss: 26.1209 - classification_loss: 4.2460 - mi_loss: 0.5257 - val_loss: 3.0067 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_classification_loss: 0.0000e+00 - val_mi_loss: 0.0000e+00\n",
      "Epoch 55/80\n",
      "1175/1184 [============================>.] - ETA: 0s - loss: 14737089.0000 - reconstruction_loss: 14736319.0000 - kl_loss: 25.8025 - classification_loss: 3.8149 - mi_loss: 0.5093Epoch 55: CF Preservation Rate = 1.0000\n",
      "1184/1184 [==============================] - 3s 2ms/step - loss: 14697172.0000 - reconstruction_loss: 14687872.0000 - kl_loss: 25.8065 - classification_loss: 3.8110 - mi_loss: 0.5094 - val_loss: 2.9987 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_classification_loss: 0.0000e+00 - val_mi_loss: 0.0000e+00\n",
      "Epoch 56/80\n",
      "1180/1184 [============================>.] - ETA: 0s - loss: 14300254.0000 - reconstruction_loss: 14299508.0000 - kl_loss: 25.8880 - classification_loss: 3.7205 - mi_loss: 0.5157Epoch 56: CF Preservation Rate = 1.0000\n",
      "1184/1184 [==============================] - 3s 2ms/step - loss: 14333337.0000 - reconstruction_loss: 14324288.0000 - kl_loss: 25.8916 - classification_loss: 3.7207 - mi_loss: 0.5156 - val_loss: 2.5581 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_classification_loss: 0.0000e+00 - val_mi_loss: 0.0000e+00\n",
      "Epoch 57/80\n",
      "1171/1184 [============================>.] - ETA: 0s - loss: 13576078.0000 - reconstruction_loss: 13575324.0000 - kl_loss: 25.7827 - classification_loss: 3.7445 - mi_loss: 0.5122Epoch 57: CF Preservation Rate = 1.0000\n",
      "1184/1184 [==============================] - 3s 2ms/step - loss: 13497572.0000 - reconstruction_loss: 13490824.0000 - kl_loss: 25.7852 - classification_loss: 3.7507 - mi_loss: 0.5122 - val_loss: 2.7460 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_classification_loss: 0.0000e+00 - val_mi_loss: 0.0000e+00\n",
      "Epoch 58/80\n",
      "1175/1184 [============================>.] - ETA: 0s - loss: 13055390.0000 - reconstruction_loss: 13054613.0000 - kl_loss: 25.9560 - classification_loss: 3.9081 - mi_loss: 0.5168Epoch 58: CF Preservation Rate = 1.0000\n",
      "1184/1184 [==============================] - 3s 3ms/step - loss: 13020577.0000 - reconstruction_loss: 13012470.0000 - kl_loss: 25.9484 - classification_loss: 3.8955 - mi_loss: 0.5168 - val_loss: 2.9104 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_classification_loss: 0.0000e+00 - val_mi_loss: 0.0000e+00\n",
      "Epoch 59/80\n",
      "1176/1184 [============================>.] - ETA: 0s - loss: 13209469.0000 - reconstruction_loss: 13208696.0000 - kl_loss: 26.0126 - classification_loss: 3.8073 - mi_loss: 0.5157Epoch 59: CF Preservation Rate = 1.0000\n",
      "1184/1184 [==============================] - 3s 2ms/step - loss: 13128241.0000 - reconstruction_loss: 13119949.0000 - kl_loss: 26.0252 - classification_loss: 3.8114 - mi_loss: 0.5159 - val_loss: 2.3432 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_classification_loss: 0.0000e+00 - val_mi_loss: 0.0000e+00\n",
      "Epoch 60/80\n",
      "1166/1184 [============================>.] - ETA: 0s - loss: 12304229.0000 - reconstruction_loss: 12303566.0000 - kl_loss: 25.9358 - classification_loss: 3.2962 - mi_loss: 0.5185Epoch 60: CF Preservation Rate = 1.0000\n",
      "1184/1184 [==============================] - 2s 2ms/step - loss: 12458660.0000 - reconstruction_loss: 12450833.0000 - kl_loss: 25.9270 - classification_loss: 3.2887 - mi_loss: 0.5184 - val_loss: 2.3017 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_classification_loss: 0.0000e+00 - val_mi_loss: 0.0000e+00\n",
      "Epoch 61/80\n",
      "1168/1184 [============================>.] - ETA: 0s - loss: 11389423.0000 - reconstruction_loss: 11388705.0000 - kl_loss: 25.6686 - classification_loss: 3.5849 - mi_loss: 0.5121Epoch 61: CF Preservation Rate = 1.0000\n",
      "1184/1184 [==============================] - 3s 3ms/step - loss: 11668615.0000 - reconstruction_loss: 11661164.0000 - kl_loss: 25.6649 - classification_loss: 3.6375 - mi_loss: 0.5120 - val_loss: 2.7028 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_classification_loss: 0.0000e+00 - val_mi_loss: 0.0000e+00\n",
      "Epoch 62/80\n",
      "1172/1184 [============================>.] - ETA: 0s - loss: 11837701.0000 - reconstruction_loss: 11837008.0000 - kl_loss: 26.0696 - classification_loss: 3.4818 - mi_loss: 0.5131Epoch 62: CF Preservation Rate = 1.0000\n",
      "1184/1184 [==============================] - 3s 3ms/step - loss: 11775592.0000 - reconstruction_loss: 11768067.0000 - kl_loss: 26.0811 - classification_loss: 3.4795 - mi_loss: 0.5131 - val_loss: 2.5001 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_classification_loss: 0.0000e+00 - val_mi_loss: 0.0000e+00\n",
      "Epoch 63/80\n",
      "1177/1184 [============================>.] - ETA: 0s - loss: 10927425.0000 - reconstruction_loss: 10926753.0000 - kl_loss: 26.1416 - classification_loss: 3.3447 - mi_loss: 0.5104Epoch 63: CF Preservation Rate = 1.0000\n",
      "1184/1184 [==============================] - 3s 2ms/step - loss: 10969031.0000 - reconstruction_loss: 10971702.0000 - kl_loss: 26.1269 - classification_loss: 3.3451 - mi_loss: 0.5101 - val_loss: 2.3181 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_classification_loss: 0.0000e+00 - val_mi_loss: 0.0000e+00\n",
      "Epoch 64/80\n",
      "1179/1184 [============================>.] - ETA: 0s - loss: 10432044.0000 - reconstruction_loss: 10431266.0000 - kl_loss: 26.1641 - classification_loss: 3.8438 - mi_loss: 0.5054Epoch 64: CF Preservation Rate = 1.0000\n",
      "1184/1184 [==============================] - 3s 2ms/step - loss: 10394226.0000 - reconstruction_loss: 10387676.0000 - kl_loss: 26.1676 - classification_loss: 3.8593 - mi_loss: 0.5054 - val_loss: 2.7397 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_classification_loss: 0.0000e+00 - val_mi_loss: 0.0000e+00\n",
      "Epoch 65/80\n",
      "1182/1184 [============================>.] - ETA: 0s - loss: 10643977.0000 - reconstruction_loss: 10643226.0000 - kl_loss: 25.8388 - classification_loss: 3.7049 - mi_loss: 0.5097Epoch 65: CF Preservation Rate = 1.0000\n",
      "1184/1184 [==============================] - 3s 2ms/step - loss: 10672126.0000 - reconstruction_loss: 10665565.0000 - kl_loss: 25.8323 - classification_loss: 3.7044 - mi_loss: 0.5094 - val_loss: 2.2936 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_classification_loss: 0.0000e+00 - val_mi_loss: 0.0000e+00\n",
      "Epoch 66/80\n",
      "1181/1184 [============================>.] - ETA: 0s - loss: 9763362.0000 - reconstruction_loss: 9762617.0000 - kl_loss: 26.2361 - classification_loss: 3.7624 - mi_loss: 0.5065Epoch 66: CF Preservation Rate = 1.0000\n",
      "1184/1184 [==============================] - 3s 3ms/step - loss: 9744294.0000 - reconstruction_loss: 9737903.0000 - kl_loss: 26.2491 - classification_loss: 3.7564 - mi_loss: 0.5064 - val_loss: 1.9323 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_classification_loss: 0.0000e+00 - val_mi_loss: 0.0000e+00\n",
      "Epoch 67/80\n",
      "1183/1184 [============================>.] - ETA: 0s - loss: 9304688.0000 - reconstruction_loss: 9303958.0000 - kl_loss: 25.8355 - classification_loss: 3.6553 - mi_loss: 0.5117Epoch 67: CF Preservation Rate = 1.0000\n",
      "1184/1184 [==============================] - 3s 3ms/step - loss: 9302392.0000 - reconstruction_loss: 9296615.0000 - kl_loss: 25.8323 - classification_loss: 3.6556 - mi_loss: 0.5116 - val_loss: 2.5619 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_classification_loss: 0.0000e+00 - val_mi_loss: 0.0000e+00\n",
      "Epoch 68/80\n",
      "1161/1184 [============================>.] - ETA: 0s - loss: 8539593.0000 - reconstruction_loss: 8538778.0000 - kl_loss: 25.6857 - classification_loss: 4.0412 - mi_loss: 0.5139Epoch 68: CF Preservation Rate = 1.0000\n",
      "1184/1184 [==============================] - 3s 3ms/step - loss: 8477658.0000 - reconstruction_loss: 8472038.0000 - kl_loss: 25.6877 - classification_loss: 4.0244 - mi_loss: 0.5138 - val_loss: 2.2913 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_classification_loss: 0.0000e+00 - val_mi_loss: 0.0000e+00\n",
      "Epoch 69/80\n",
      "1182/1184 [============================>.] - ETA: 0s - loss: 7893650.5000 - reconstruction_loss: 7892887.0000 - kl_loss: 25.6976 - classification_loss: 3.8563 - mi_loss: 0.5127Epoch 69: CF Preservation Rate = 1.0000\n",
      "1184/1184 [==============================] - 3s 2ms/step - loss: 7885051.5000 - reconstruction_loss: 7879767.5000 - kl_loss: 25.6999 - classification_loss: 3.8545 - mi_loss: 0.5127 - val_loss: 1.9616 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_classification_loss: 0.0000e+00 - val_mi_loss: 0.0000e+00\n",
      "Epoch 70/80\n",
      "1176/1184 [============================>.] - ETA: 0s - loss: 8167606.0000 - reconstruction_loss: 8166892.0000 - kl_loss: 25.1632 - classification_loss: 3.5579 - mi_loss: 0.5171Epoch 70: CF Preservation Rate = 1.0000\n",
      "1184/1184 [==============================] - 3s 3ms/step - loss: 8178672.5000 - reconstruction_loss: 8173214.5000 - kl_loss: 25.1721 - classification_loss: 3.5577 - mi_loss: 0.5169 - val_loss: 2.0570 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_classification_loss: 0.0000e+00 - val_mi_loss: 0.0000e+00\n",
      "Epoch 71/80\n",
      "1179/1184 [============================>.] - ETA: 0s - loss: 6994911.5000 - reconstruction_loss: 6994178.5000 - kl_loss: 25.0870 - classification_loss: 3.6981 - mi_loss: 0.5117Epoch 71: CF Preservation Rate = 1.0000\n",
      "1184/1184 [==============================] - 3s 2ms/step - loss: 6993618.0000 - reconstruction_loss: 6988920.0000 - kl_loss: 25.0933 - classification_loss: 3.6892 - mi_loss: 0.5116 - val_loss: 2.2714 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_classification_loss: 0.0000e+00 - val_mi_loss: 0.0000e+00\n",
      "Epoch 72/80\n",
      "1165/1184 [============================>.] - ETA: 0s - loss: 7459271.5000 - reconstruction_loss: 7458604.0000 - kl_loss: 25.5021 - classification_loss: 3.3889 - mi_loss: 0.5079Epoch 72: CF Preservation Rate = 1.0000\n",
      "1184/1184 [==============================] - 3s 3ms/step - loss: 7425089.0000 - reconstruction_loss: 7420136.5000 - kl_loss: 25.5262 - classification_loss: 3.3859 - mi_loss: 0.5080 - val_loss: 2.1099 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_classification_loss: 0.0000e+00 - val_mi_loss: 0.0000e+00\n",
      "Epoch 73/80\n",
      "1178/1184 [============================>.] - ETA: 0s - loss: 6081627.0000 - reconstruction_loss: 6080916.0000 - kl_loss: 25.6509 - classification_loss: 3.5585 - mi_loss: 0.4998Epoch 73: CF Preservation Rate = 1.0000\n",
      "1184/1184 [==============================] - 3s 3ms/step - loss: 6055073.5000 - reconstruction_loss: 6051994.0000 - kl_loss: 25.6630 - classification_loss: 3.5617 - mi_loss: 0.4999 - val_loss: 2.4749 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_classification_loss: 0.0000e+00 - val_mi_loss: 0.0000e+00\n",
      "Epoch 74/80\n",
      "1162/1184 [============================>.] - ETA: 0s - loss: 6854247.5000 - reconstruction_loss: 6853475.5000 - kl_loss: 25.8218 - classification_loss: 3.8632 - mi_loss: 0.5043Epoch 74: CF Preservation Rate = 1.0000\n",
      "1184/1184 [==============================] - 3s 2ms/step - loss: 6771255.5000 - reconstruction_loss: 6766586.0000 - kl_loss: 25.8388 - classification_loss: 3.9320 - mi_loss: 0.5046 - val_loss: 2.0812 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_classification_loss: 0.0000e+00 - val_mi_loss: 0.0000e+00\n",
      "Epoch 75/80\n",
      "1168/1184 [============================>.] - ETA: 0s - loss: 5924535.0000 - reconstruction_loss: 5923739.5000 - kl_loss: 25.4739 - classification_loss: 3.9950 - mi_loss: 0.5125Epoch 75: CF Preservation Rate = 1.0000\n",
      "1184/1184 [==============================] - 3s 2ms/step - loss: 5884875.5000 - reconstruction_loss: 5880702.0000 - kl_loss: 25.4631 - classification_loss: 4.0093 - mi_loss: 0.5123 - val_loss: 2.7774 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_classification_loss: 0.0000e+00 - val_mi_loss: 0.0000e+00\n",
      "Epoch 76/80\n",
      "1173/1184 [============================>.] - ETA: 0s - loss: 5863146.5000 - reconstruction_loss: 5862414.5000 - kl_loss: 25.4302 - classification_loss: 3.6965 - mi_loss: 0.5152Epoch 76: CF Preservation Rate = 1.0000\n",
      "1184/1184 [==============================] - 3s 2ms/step - loss: 5989372.5000 - reconstruction_loss: 5985400.0000 - kl_loss: 25.4016 - classification_loss: 3.7130 - mi_loss: 0.5148 - val_loss: 2.8440 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_classification_loss: 0.0000e+00 - val_mi_loss: 0.0000e+00\n",
      "Epoch 77/80\n",
      "1174/1184 [============================>.] - ETA: 0s - loss: 4674476.0000 - reconstruction_loss: 4673808.0000 - kl_loss: 25.3820 - classification_loss: 3.3464 - mi_loss: 0.5145Epoch 77: CF Preservation Rate = 1.0000\n",
      "1184/1184 [==============================] - 3s 2ms/step - loss: 4687079.0000 - reconstruction_loss: 4683692.5000 - kl_loss: 25.3623 - classification_loss: 3.3376 - mi_loss: 0.5143 - val_loss: 2.4593 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_classification_loss: 0.0000e+00 - val_mi_loss: 0.0000e+00\n",
      "Epoch 78/80\n",
      "1177/1184 [============================>.] - ETA: 0s - loss: 5057886.5000 - reconstruction_loss: 5057198.0000 - kl_loss: 24.9518 - classification_loss: 3.4466 - mi_loss: 0.5100Epoch 78: CF Preservation Rate = 1.0000\n",
      "1184/1184 [==============================] - 3s 2ms/step - loss: 5046793.5000 - reconstruction_loss: 5043173.5000 - kl_loss: 24.9503 - classification_loss: 3.4729 - mi_loss: 0.5099 - val_loss: 2.5609 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_classification_loss: 0.0000e+00 - val_mi_loss: 0.0000e+00\n",
      "Epoch 79/80\n",
      "1183/1184 [============================>.] - ETA: 0s - loss: 4080645.7500 - reconstruction_loss: 4079884.2500 - kl_loss: 25.3059 - classification_loss: 3.7895 - mi_loss: 0.5159Epoch 79: CF Preservation Rate = 1.0000\n",
      "1184/1184 [==============================] - 3s 3ms/step - loss: 4079718.5000 - reconstruction_loss: 4076919.2500 - kl_loss: 25.3036 - classification_loss: 3.7896 - mi_loss: 0.5159 - val_loss: 2.8935 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_classification_loss: 0.0000e+00 - val_mi_loss: 0.0000e+00\n",
      "Epoch 80/80\n",
      "1183/1184 [============================>.] - ETA: 0s - loss: 4217265.0000 - reconstruction_loss: 4216429.0000 - kl_loss: 25.7442 - classification_loss: 4.1858 - mi_loss: 0.5368Epoch 80: CF Preservation Rate = 1.0000\n",
      "1184/1184 [==============================] - 3s 3ms/step - loss: 4216153.0000 - reconstruction_loss: 4212869.0000 - kl_loss: 25.7539 - classification_loss: 4.1911 - mi_loss: 0.5368 - val_loss: 2.9565 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_classification_loss: 0.0000e+00 - val_mi_loss: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1553aa418390>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.metrics import accuracy_score\n",
    "from itertools import combinations\n",
    "from scipy.stats import gumbel_r\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "clf = load_model('clf.h5')\n",
    "\n",
    "\n",
    "data = pd.read_csv('adult.csv')\n",
    "data.drop(['fnlwgt', 'workclass', 'occupation', 'native-country'], axis = 1, inplace = True)\n",
    "\n",
    "le = LabelEncoder()\n",
    "data['education'], data['marital-status'], data['relationship'], data['race'], data['gender'], data['income'] = le.fit_transform(data['education']), le.fit_transform(data['marital-status']), le.fit_transform(data['relationship']), le.fit_transform(data['race']), le.fit_transform(data['gender']), le.fit_transform(data['income'])\n",
    "\n",
    "to_remove = data[data['income'] == 0].sample(n=25468, random_state=42)\n",
    "data = data.drop(to_remove.index)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.loc[:,:'hours-per-week'].values, data.loc[:,'income'].values, test_size=0.1, random_state=42)\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "# Evaluate classifier\n",
    "y_train_pred = np.argmax(clf.predict(X_train), axis=1)\n",
    "y_test_pred = np.argmax(clf.predict(X_test), axis=1)\n",
    "print(\"Train accuracy:\", accuracy_score(np.argmax(y_train, axis=1), y_train_pred))\n",
    "print(\"Test accuracy:\", accuracy_score(np.argmax(y_test, axis=1), y_test_pred))\n",
    "\n",
    "# Freeze classifier\n",
    "for layer in clf.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Standardize continuous features\n",
    "continuous_indices = [0, 2, 7, 8, 9]  # age, education-num, capital-gain, capital-loss, hours-per-week\n",
    "categorical_indices = [1, 3, 4, 5, 6]  # education, marital-status, relationship, race, gender\n",
    "\n",
    "# Ensure X_train and X_test are float32\n",
    "X_train = X_train.astype(np.float32)\n",
    "X_test = X_test.astype(np.float32)\n",
    "\n",
    "# Check for nan or inf in data\n",
    "if np.any(np.isnan(X_train)) or np.any(np.isinf(X_train)):\n",
    "    raise ValueError(\"X_train contains nan or inf values\")\n",
    "if np.any(np.isnan(X_test)) or np.any(np.isinf(X_test)):\n",
    "    raise ValueError(\"X_test contains nan or inf values\")\n",
    "\n",
    "# Define cardinalities (hard-coded for Adult dataset)\n",
    "cardinalities = {\n",
    "    1: 16,  # education\n",
    "    3: 7,   # marital-status\n",
    "    4: 6,   # relationship\n",
    "    5: 5,   # race\n",
    "    6: 2    # gender\n",
    "}\n",
    "\n",
    "# Compute feature weights for continuous features (inverse std, post-scaling)\n",
    "feature_std = np.std(X_train[:, continuous_indices], axis=0)\n",
    "feature_weights = np.ones(10, dtype=np.float32)\n",
    "feature_weights[continuous_indices] = 1.0 / (feature_std + 1e-10)\n",
    "feature_weights[categorical_indices] = 1.0\n",
    "\n",
    "# Evaluate classifier\n",
    "y_train_pred = np.argmax(clf.predict(X_train), axis=1)\n",
    "y_test_pred = np.argmax(clf.predict(X_test), axis=1)\n",
    "print(\"Train accuracy:\", accuracy_score(np.argmax(y_train, axis=1), y_train_pred))\n",
    "print(\"Test accuracy:\", accuracy_score(np.argmax(y_test, axis=1), y_test_pred))\n",
    "\n",
    "# Function to estimate mutual information for continuous feature pairs\n",
    "def estimate_mi(x, y, bins=50):\n",
    "    hist_2d, x_edges, y_edges = np.histogram2d(x, y, bins=bins, density=True)\n",
    "    p_xy = hist_2d / np.sum(hist_2d + 1e-5) + 1e-5\n",
    "    p_x = np.sum(p_xy, axis=1)\n",
    "    p_y = np.sum(p_xy, axis=0)\n",
    "    p_x_p_y = np.outer(p_x, p_y) + 1e-5\n",
    "    valid = (p_xy > 1e-5) & (p_x_p_y > 1e-5)\n",
    "    mi = np.sum(p_xy[valid] * np.log(p_xy[valid] / p_x_p_y[valid]))\n",
    "    return np.clip(mi, 0, 5)\n",
    "\n",
    "# Precompute MI for continuous feature pairs\n",
    "n_features = X_train.shape[1]\n",
    "mi_original = {}\n",
    "feature_ranges = {}\n",
    "for i, j in combinations(continuous_indices, 2):\n",
    "    mi = estimate_mi(X_train[:, i], X_train[:, j], bins=50)\n",
    "    mi_original[(i, j)] = mi\n",
    "    feature_ranges[(i, j)] = (\n",
    "        min(X_train[:, i].min(), X_train[:, j].min()),\n",
    "        max(X_train[:, i].max(), X_train[:, j].max())\n",
    "    )\n",
    "\n",
    "mi_original_tf = {k: tf.constant(v, dtype=tf.float32) for k, v in mi_original.items()}\n",
    "\n",
    "# Hyperparameters\n",
    "latent_dim = 20\n",
    "lambda_classification = 200.0\n",
    "lambda_mi = 6\n",
    "lambda_mse = 4\n",
    "lambda_fixed = 0.5\n",
    "lambda_kl = 0.00001 #0.0000001\n",
    "n_fixed = 2\n",
    "bins = 50\n",
    "\n",
    "# Custom MI Loss Layer\n",
    "class MILossLayer(keras.layers.Layer):\n",
    "    def __init__(self, continuous_indices, feature_ranges, mi_original_tf, bins=50, lambda_mi=0.1, **kwargs):\n",
    "        super(MILossLayer, self).__init__(**kwargs)\n",
    "        self.continuous_indices = continuous_indices\n",
    "        self.feature_ranges = feature_ranges\n",
    "        self.mi_original_tf = mi_original_tf\n",
    "        self.bins = bins\n",
    "        self.lambda_mi = lambda_mi\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x_recon = inputs\n",
    "        mi_loss = 0.0\n",
    "        for i, j in combinations(self.continuous_indices, 2):\n",
    "            x_i = x_recon[:, i]\n",
    "            x_j = x_recon[:, j]\n",
    "            vmin, vmax = self.feature_ranges[(i, j)]\n",
    "            vmin = tf.constant(vmin, dtype=tf.float32)\n",
    "            vmax = tf.constant(vmax, dtype=tf.float32)\n",
    "            bin_edges = tf.linspace(vmin, vmax, self.bins + 1)\n",
    "            x_i_bin = tf.searchsorted(bin_edges, x_i, side='right') - 1\n",
    "            x_j_bin = tf.searchsorted(bin_edges, x_j, side='right') - 1\n",
    "            x_i_bin = tf.clip_by_value(x_i_bin, 0, self.bins - 1)\n",
    "            x_j_bin = tf.clip_by_value(x_j_bin, 0, self.bins - 1)\n",
    "            flat_indices = x_i_bin * bins + x_j_bin\n",
    "            flat_indices = tf.cast(flat_indices, tf.int32)\n",
    "            hist_1d = tf.math.bincount(flat_indices, minlength=bins * bins)\n",
    "            hist_2d = tf.reshape(hist_1d, (bins, bins))\n",
    "            hist_2d = tf.cast(hist_2d, tf.float32) + 1e-5\n",
    "            p_xy = hist_2d / (tf.reduce_sum(hist_2d) + 1e-5)\n",
    "            p_x = tf.reduce_sum(p_xy, axis=1) + 1e-5\n",
    "            p_y = tf.reduce_sum(p_xy, axis=0) + 1e-5\n",
    "            p_x_p_y = tf.expand_dims(p_x, 1) * tf.expand_dims(p_y, 0)\n",
    "            valid = (p_xy > 1e-5) & (p_x_p_y > 1e-5)\n",
    "            mi = tf.reduce_sum(tf.where(valid, p_xy * tf.math.log(p_xy / p_x_p_y), 0.0))\n",
    "            mi_loss += tf.abs(tf.clip_by_value(mi - self.mi_original_tf[(i, j)], -5, 5))\n",
    "        mi_loss = mi_loss / (len(self.mi_original_tf) + 1e-10)\n",
    "        self.add_loss(self.lambda_mi * mi_loss)\n",
    "        return x_recon\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(MILossLayer, self).get_config()\n",
    "        config.update({\n",
    "            'continuous_indices': self.continuous_indices,\n",
    "            'feature_ranges': self.feature_ranges,\n",
    "            'mi_original_tf': {k: v.numpy() for k, v in self.mi_original_tf.items()},\n",
    "            'bins': self.bins,\n",
    "            'lambda_mi': self.lambda_mi\n",
    "        })\n",
    "        return config\n",
    "\n",
    "# Custom VAE Model\n",
    "class VAE(keras.Model):\n",
    "    def __init__(self, encoder, decoder, clf, continuous_indices, categorical_indices, feature_weights, lambda_classification, lambda_kl, lambda_mse, lambda_fixed, lambda_mi, **kwargs):\n",
    "        super(VAE, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.clf = clf\n",
    "        self.continuous_indices = continuous_indices\n",
    "        self.categorical_indices = categorical_indices\n",
    "        self.feature_weights = tf.constant(feature_weights, dtype=tf.float32)\n",
    "        self.lambda_classification = lambda_classification\n",
    "        self.lambda_kl = lambda_kl\n",
    "        self.lambda_mse = lambda_mse\n",
    "        self.lambda_fixed = lambda_fixed\n",
    "        self.lambda_mi = lambda_mi\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(name=\"reconstruction_loss\")\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
    "        self.classification_loss_tracker = keras.metrics.Mean(name=\"classification_loss\")\n",
    "        self.mi_loss_tracker = keras.metrics.Mean(name=\"mi_loss\")\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        vae_inputs, t_inputs, mask_inputs = inputs\n",
    "        mu, log_var = self.encoder(vae_inputs)\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(tf.shape(mu)[0], latent_dim))\n",
    "        z = mu + tf.exp(0.5 * tf.clip_by_value(log_var, -10, 10)) * epsilon\n",
    "        decoder_outputs = self.decoder([z, t_inputs, mask_inputs, vae_inputs])\n",
    "        x_recon = decoder_outputs[0]\n",
    "        CF = decoder_outputs[1]\n",
    "        logits_list = decoder_outputs[2:]\n",
    "        return x_recon, CF, logits_list, mu, log_var\n",
    "\n",
    "    def train_step(self, data):\n",
    "        (vae_inputs, t_inputs, mask_inputs), y_true = data\n",
    "        with tf.GradientTape() as tape:\n",
    "            x_recon, CF, logits_list, mu, log_var = self([vae_inputs, t_inputs, mask_inputs], training=True)\n",
    "\n",
    "            # Fixed Feature Reconstruction Loss\n",
    "            batch_size = tf.shape(mask_inputs)[0]\n",
    "            fixed_recon_loss_continuous = tf.zeros([], dtype=tf.float32)\n",
    "            fixed_recon_loss_categorical = tf.zeros([], dtype=tf.float32)\n",
    "\n",
    "            # Continuous features\n",
    "            continuous_mask = tf.zeros_like(mask_inputs, dtype=tf.float32)\n",
    "            for idx in self.continuous_indices:\n",
    "                indices = tf.stack([\n",
    "                    tf.range(batch_size),\n",
    "                    tf.fill([batch_size], tf.cast(idx, tf.int32))\n",
    "                ], axis=1)\n",
    "                continuous_mask = tf.tensor_scatter_nd_update(\n",
    "                    continuous_mask,\n",
    "                    indices,\n",
    "                    tf.ones([batch_size], dtype=tf.float32)\n",
    "                )\n",
    "            continuous_mask = continuous_mask * mask_inputs\n",
    "            fixed_recon_loss_continuous = tf.reduce_mean(\n",
    "                tf.reduce_sum(continuous_mask * tf.square(vae_inputs - x_recon), axis=1)\n",
    "            )\n",
    "\n",
    "            # Categorical features\n",
    "            categorical_mask = tf.zeros_like(mask_inputs, dtype=tf.float32)\n",
    "            for idx in self.categorical_indices:\n",
    "                indices = tf.stack([\n",
    "                    tf.range(batch_size),\n",
    "                    tf.fill([batch_size], tf.cast(idx, tf.int32))\n",
    "                ], axis=1)\n",
    "                categorical_mask = tf.tensor_scatter_nd_update(\n",
    "                    categorical_mask,\n",
    "                    indices,\n",
    "                    tf.ones([batch_size], dtype=tf.float32)\n",
    "                )\n",
    "            categorical_mask = categorical_mask * mask_inputs\n",
    "            categorical_errors = tf.zeros([batch_size], dtype=tf.float32)\n",
    "            for idx, cat_idx in enumerate(self.categorical_indices):\n",
    "                logits = logits_list[idx]\n",
    "                true = tf.cast(vae_inputs[:, cat_idx], tf.int32)\n",
    "                cat_loss = tf.keras.losses.sparse_categorical_crossentropy(true, logits)\n",
    "                cat_mask = categorical_mask[:, cat_idx]\n",
    "                categorical_errors += cat_mask * cat_loss\n",
    "            fixed_recon_loss_categorical = tf.reduce_mean(categorical_errors)\n",
    "\n",
    "            fixed_recon_loss = (fixed_recon_loss_continuous + fixed_recon_loss_categorical) / 10\n",
    "            fixed_recon_loss = self.lambda_fixed * fixed_recon_loss\n",
    "\n",
    "            # Mutable Feature Reconstruction Loss\n",
    "            mutable_recon_loss_continuous = tf.zeros([], dtype=tf.float32)\n",
    "            mutable_recon_loss_categorical = tf.zeros([], dtype=tf.float32)\n",
    "\n",
    "            # Continuous features\n",
    "            mutable_continuous_mask = tf.zeros_like(mask_inputs, dtype=tf.float32)\n",
    "            for idx in self.continuous_indices:\n",
    "                indices = tf.stack([\n",
    "                    tf.range(batch_size),\n",
    "                    tf.fill([batch_size], tf.cast(idx, tf.int32))\n",
    "                ], axis=1)\n",
    "                mutable_continuous_mask = tf.tensor_scatter_nd_update(\n",
    "                    mutable_continuous_mask,\n",
    "                    indices,\n",
    "                    tf.ones([batch_size], dtype=tf.float32)\n",
    "                )\n",
    "            mutable_continuous_mask = mutable_continuous_mask * (1 - mask_inputs)\n",
    "            mutable_recon_loss_continuous = tf.reduce_mean(\n",
    "                tf.reduce_sum(mutable_continuous_mask * tf.square(vae_inputs - x_recon), axis=1)\n",
    "            )\n",
    "\n",
    "            # Categorical features\n",
    "            mutable_categorical_mask = tf.zeros_like(mask_inputs, dtype=tf.float32)\n",
    "            for idx in self.categorical_indices:\n",
    "                indices = tf.stack([\n",
    "                    tf.range(batch_size),\n",
    "                    tf.fill([batch_size], tf.cast(idx, tf.int32))\n",
    "                ], axis=1)\n",
    "                mutable_categorical_mask = tf.tensor_scatter_nd_update(\n",
    "                    mutable_categorical_mask,\n",
    "                    indices,\n",
    "                    tf.ones([batch_size], dtype=tf.float32)\n",
    "                )\n",
    "            mutable_categorical_mask = mutable_categorical_mask * (1 - mask_inputs)\n",
    "            mutable_categorical_errors = tf.zeros([batch_size], dtype=tf.float32)\n",
    "            for idx, cat_idx in enumerate(self.categorical_indices):\n",
    "                logits = logits_list[idx]\n",
    "                true = tf.cast(vae_inputs[:, cat_idx], tf.int32)\n",
    "                cat_loss = tf.keras.losses.sparse_categorical_crossentropy(true, logits)\n",
    "                cat_mask = mutable_categorical_mask[:, cat_idx]\n",
    "                mutable_categorical_errors += cat_mask * cat_loss\n",
    "            mutable_recon_loss_categorical = tf.reduce_mean(mutable_categorical_errors)\n",
    "\n",
    "            mutable_recon_loss = (mutable_recon_loss_continuous + mutable_recon_loss_categorical) / 10\n",
    "            mutable_recon_loss = self.lambda_mse * mutable_recon_loss\n",
    "\n",
    "            # KL Divergence Loss\n",
    "            kl_loss = tf.reduce_mean(tf.square(mu) + tf.exp(log_var) - log_var - 1.0)\n",
    "\n",
    "            # Classification Loss (on CF)\n",
    "            p = self.clf(CF)\n",
    "            classification_loss = tf.keras.losses.sparse_categorical_crossentropy(tf.squeeze(t_inputs, axis=-1), p)\n",
    "\n",
    "            # Total Loss (MI loss is added via MILossLayer)\n",
    "            total_loss = mutable_recon_loss + self.lambda_kl * kl_loss + self.lambda_classification * classification_loss + fixed_recon_loss\n",
    "\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "\n",
    "        # Update metrics\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(mutable_recon_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        self.classification_loss_tracker.update_state(classification_loss)\n",
    "        mi_loss = sum(self.losses) / self.lambda_mi if self.losses else 0.0\n",
    "        self.mi_loss_tracker.update_state(mi_loss)\n",
    "\n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "            \"classification_loss\": self.classification_loss_tracker.result(),\n",
    "            \"mi_loss\": self.mi_loss_tracker.result(),\n",
    "        }\n",
    "\n",
    "# Encoder\n",
    "encoder_inputs = keras.Input(shape=(10,), dtype=tf.float32, name='X')\n",
    "x = keras.layers.Dense(64, activation='relu')(encoder_inputs)\n",
    "x = keras.layers.BatchNormalization(momentum=0.9)(x)\n",
    "x = keras.layers.Dense(32, activation='relu')(x)\n",
    "x = keras.layers.BatchNormalization(momentum=0.9)(x)\n",
    "mu = keras.layers.Dense(latent_dim, name='mu')(x)\n",
    "log_var = keras.layers.Dense(latent_dim, name='log_var')(x)\n",
    "encoder = keras.Model(encoder_inputs, [mu, log_var], name='encoder')\n",
    "\n",
    "# Decoder\n",
    "z_inputs = keras.Input(shape=(latent_dim,), name='z')\n",
    "t_inputs = keras.Input(shape=(1,), name='t')\n",
    "mask_inputs = keras.Input(shape=(10,), name='mask')\n",
    "vae_inputs = keras.Input(shape=(10,), dtype=tf.float32, name='X_input')\n",
    "decoder_inputs = keras.layers.Concatenate(name='decoder_input')([z_inputs, t_inputs])\n",
    "x = keras.layers.Dense(32, activation='relu')(decoder_inputs)\n",
    "x = keras.layers.BatchNormalization(momentum=0.9)(x)\n",
    "x = keras.layers.Dense(64, activation='relu')(x)\n",
    "x = keras.layers.BatchNormalization(momentum=0.9)(x)\n",
    "\n",
    "outputs = []\n",
    "logits_outputs = []\n",
    "for i in range(10):\n",
    "    if i in continuous_indices:\n",
    "        # Apply Dense layer and enforce non-negativity with ReLU\n",
    "        out = keras.layers.Dense(1, name=f'X{i}_recon')(x)\n",
    "        out = tf.nn.relu(out)  # Ensure non-negative output\n",
    "        outputs.append(out)\n",
    "    else:\n",
    "        # Categorical features are already non-negative (indices 0, 1, 2, ...)\n",
    "        logits = keras.layers.Dense(cardinalities[i], name=f'X{i}_logits')(x)\n",
    "        logits = tf.clip_by_value(logits, -10, 10)\n",
    "        out = tf.cast(tf.argmax(logits, axis=-1), tf.float32, name=f'X{i}_recon')\n",
    "        out = tf.expand_dims(out, axis=-1)\n",
    "        outputs.append(out)\n",
    "        logits_outputs.append(logits)\n",
    "\n",
    "x_recon = keras.layers.Concatenate(name='X_recon')(outputs)\n",
    "x_recon = MILossLayer(continuous_indices, feature_ranges, mi_original_tf, bins=bins, lambda_mi=lambda_mi)(x_recon)\n",
    "CF = mask_inputs * vae_inputs + (1 - mask_inputs) * x_recon\n",
    "decoder = keras.Model([z_inputs, t_inputs, mask_inputs, vae_inputs], [x_recon, CF] + logits_outputs, name='decoder')\n",
    "\n",
    "# Instantiate VAE\n",
    "vae = VAE(\n",
    "    encoder=encoder,\n",
    "    decoder=decoder,\n",
    "    clf=clf,\n",
    "    continuous_indices=continuous_indices,\n",
    "    categorical_indices=categorical_indices,\n",
    "    feature_weights=feature_weights,\n",
    "    lambda_classification=lambda_classification,\n",
    "    lambda_kl=lambda_kl,\n",
    "    lambda_mse=lambda_mse,\n",
    "    lambda_fixed=lambda_fixed,\n",
    "    lambda_mi=lambda_mi\n",
    ")\n",
    "\n",
    "# Freeze classifier\n",
    "for layer in clf.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compile VAE with gradient clipping\n",
    "vae.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-3, clipnorm=1.0))\n",
    "\n",
    "# Prepare training data\n",
    "t_train = (1 - np.argmax(clf.predict(X_train), axis=1)).reshape(-1, 1).astype(np.float32)\n",
    "\n",
    "mask_train = np.zeros((X_train.shape[0], 10), dtype=np.float32)\n",
    "indices_to_mask = [i for i in range(10) if i not in [5, 6]]\n",
    "for i in range(X_train.shape[0]):\n",
    "    fixed_indices = np.random.choice(indices_to_mask, size=n_fixed - 2, replace=False)\n",
    "    mask_train[i, fixed_indices] = 1.0\n",
    "    mask_train[i, 5] = 1.0  # race\n",
    "    mask_train[i, 6] = 1.0  # gender\n",
    "\n",
    "# Custom Callback to Monitor Preservation\n",
    "class PreservationCallback(keras.callbacks.Callback):\n",
    "    def __init__(self, X_val, t_val, mask_val, tolerance=1e-5):\n",
    "        super().__init__()\n",
    "        self.X_val = X_val\n",
    "        self.t_val = t_val\n",
    "        self.mask_val = mask_val\n",
    "        self.tolerance = tolerance\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        x_recon_val, CF_val, _, _, _ = self.model.predict([self.X_val, self.t_val, self.mask_val], verbose=0)\n",
    "        diff_cf = np.abs(self.X_val - CF_val) * self.mask_val\n",
    "        preserved_cf = np.all(diff_cf <= self.tolerance, axis=1)\n",
    "        preservation_rate_cf = np.mean(preserved_cf)\n",
    "        print(f\"Epoch {epoch + 1}: CF Preservation Rate = {preservation_rate_cf:.4f}\")\n",
    "\n",
    "# Split validation data\n",
    "val_split = 0.1\n",
    "n_val = int(X_train.shape[0] * val_split)\n",
    "X_val = X_train[-n_val:]\n",
    "t_val = t_train[-n_val:]\n",
    "mask_val = mask_train[-n_val:]\n",
    "X_train = X_train[:-n_val]\n",
    "t_train = t_train[:-n_val]\n",
    "mask_train = mask_train[:-n_val]\n",
    "\n",
    "# Train VAE\n",
    "vae.fit(\n",
    "    [X_train, t_train, mask_train],\n",
    "    X_train,\n",
    "    epochs=80,\n",
    "    batch_size=16,\n",
    "    validation_data=([X_val, t_val, mask_val], None),\n",
    "    callbacks=[PreservationCallback(X_val, t_val, mask_val)],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cea61150-2b88-4cbc-8f64-e0112dc44a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74/74 [==============================] - 0s 480us/step\n",
      "Execution time: 0.0496 seconds\n",
      "74/74 [==============================] - 0s 462us/step\n",
      "74/74 [==============================] - 0s 455us/step\n",
      "Number of flips: 2262 out of 2338\n",
      "Flip rate: 0.9675\n",
      "Preservation Rate: 1.0000\n",
      "Max Difference in Fixed Features: 0.000000\n",
      "Mean Difference in Fixed Features: 0.000000\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Prepare test data\n",
    "t_test = (1 - np.argmax(clf.predict(X_test), axis=1)).reshape(-1, 1).astype(np.float32)\n",
    "\n",
    "# Generate masks for test set: fix ~4 features, race (5) and gender (6) always fixed\n",
    "n_fixed = 2\n",
    "mask_test = np.zeros((X_test.shape[0], 10), dtype=np.float32)\n",
    "indices_to_mask = [i for i in range(10) if i not in [5, 6]]\n",
    "for i in range(X_test.shape[0]):\n",
    "    fixed_indices = np.random.choice(indices_to_mask, size=n_fixed - 2, replace=False)\n",
    "    mask_test[i, fixed_indices] = 1.0\n",
    "    mask_test[i, 5] = 1.0  # race\n",
    "    mask_test[i, 6] = 1.0  # gender\n",
    "\n",
    "\n",
    "import time\n",
    "start_time = time.time()  # Record start time\n",
    "outputs = vae.predict([X_test[:100], t_test[:100], mask_test[:100]], verbose=0)\n",
    "end_time = time.time()  # Record end time\n",
    "execution_time = end_time - start_time\n",
    "print(f\"Execution time: {execution_time:.4f} seconds\")\n",
    "\n",
    "\n",
    "# Generate counterfactuals using the VAE\n",
    "outputs = vae.predict([X_test, t_test, mask_test], verbose=0)\n",
    "\n",
    "x_recon = outputs[0]  # Raw reconstruction\n",
    "X_test_recon = outputs[1]  # Counterfactual (CF) output\n",
    "\n",
    "# Get original and counterfactual predictions\n",
    "y_test_pred_orig = np.argmax(clf.predict(X_test), axis=1)\n",
    "y_test_pred_recon = np.argmax(clf.predict(X_test_recon), axis=1)\n",
    "\n",
    "# Compute flip rate\n",
    "flips = np.sum(y_test_pred_orig != y_test_pred_recon)\n",
    "flip_rate = flips / len(y_test_pred_orig)\n",
    "\n",
    "print(f\"Number of flips: {flips} out of {len(y_test_pred_orig)}\")\n",
    "print(f\"Flip rate: {flip_rate:.4f}\")\n",
    "\n",
    "# Verify preservation\n",
    "tolerance = 1e-5\n",
    "diff = np.abs(X_test - X_test_recon) * mask_test  # Differences where mask = 1\n",
    "preserved_per_sample = np.all(diff <= tolerance, axis=1)\n",
    "preservation_rate = np.mean(preserved_per_sample)\n",
    "max_diff = np.max(diff)\n",
    "mean_diff = np.sum(diff) / np.sum(mask_test) if np.sum(mask_test) > 0 else 0.0\n",
    "print(f\"Preservation Rate: {preservation_rate:.4f}\")\n",
    "print(f\"Max Difference in Fixed Features: {max_diff:.6f}\")\n",
    "print(f\"Mean Difference in Fixed Features: {mean_diff:.6f}\")\n",
    "\n",
    "# Function to plot mean absolute changes\n",
    "def plot_feature_changes(X_original, X_cf, mask, feature_names=None, save_path='feature_changes.png'):\n",
    "    \"\"\"\n",
    "    Generate a bar plot showing mean absolute changes in fixed and mutable features.\n",
    "    \"\"\"\n",
    "    n_features = X_original.shape[1]\n",
    "    if feature_names is None:\n",
    "        feature_names = [f'Feature {i}' for i in range(n_features)]\n",
    "    \n",
    "    # Compute absolute differences\n",
    "    diff = np.abs(X_original - X_cf)\n",
    "    \n",
    "    # Initialize arrays to store mean differences and counts\n",
    "    fixed_diff = np.zeros(n_features)\n",
    "    mutable_diff = np.zeros(n_features)\n",
    "    fixed_count = np.zeros(n_features)\n",
    "    mutable_count = np.zeros(n_features)\n",
    "    \n",
    "    # Calculate mean differences for fixed and mutable features\n",
    "    for i in range(n_features):\n",
    "        fixed_mask = mask[:, i] == 1\n",
    "        mutable_mask = mask[:, i] == 0\n",
    "        fixed_count[i] = np.sum(fixed_mask)\n",
    "        mutable_count[i] = np.sum(mutable_mask)\n",
    "        if fixed_count[i] > 0:\n",
    "            fixed_diff[i] = np.mean(diff[fixed_mask, i])\n",
    "        if mutable_count[i] > 0:\n",
    "            mutable_diff[i] = np.mean(diff[mutable_mask, i])\n",
    "    \n",
    "    # Plotting\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    bar_width = 0.35\n",
    "    index = np.arange(n_features)\n",
    "    \n",
    "    plt.bar(index, fixed_diff, bar_width, label='Fixed Features', color='blue', alpha=0.8)\n",
    "    plt.bar(index + bar_width, mutable_diff, bar_width, label='Mutable Features', color='orange', alpha=0.8)\n",
    "    \n",
    "    plt.xlabel('Features')\n",
    "    plt.ylabel('Mean Absolute Difference')\n",
    "    plt.title('Mean Absolute Changes in Fixed vs Mutable Features')\n",
    "    plt.xticks(index + bar_width / 2, feature_names, rotation=45)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    \n",
    "    # Add text annotations for counts\n",
    "    for i in range(n_features):\n",
    "        plt.text(i, fixed_diff[i], f'n={int(fixed_count[i])}', ha='center', va='bottom', color='blue', fontsize=8)\n",
    "        plt.text(i + bar_width, mutable_diff[i], f'n={int(mutable_count[i])}', ha='center', va='bottom', color='orange', fontsize=8)\n",
    "\n",
    "    plt.show()\n",
    "    #plt.savefig(save_path)\n",
    "    #plt.close()\n",
    "\n",
    "# Define feature names based on Adult dataset\n",
    "feature_names = ['age', 'education', 'education-num', 'marital-status', 'relationship', \n",
    "                 'race', 'gender', 'capital-gain', 'capital-loss', 'hours-per-week']\n",
    "\n",
    "# Plot the changes\n",
    "plot_feature_changes(X_test, X_test_recon, mask_test, feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "008d985d-e5bd-4a31-9541-70a68a15b9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "counterfactuals = pd.DataFrame(X_test_recon, columns = feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8abba9aa-5ae0-485c-945c-dbe513292044",
   "metadata": {},
   "source": [
    "### CES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b07b92dc-3b2a-4672-b39f-8281e9045876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Causal-Edge Score (Adult): -88.10560805696761\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import norm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "def estimate_linear_relationship(X):\n",
    "    \"\"\"\n",
    "    Estimate linear relationship: hours-per-week ≈ a * age + b\n",
    "    Returns a, b, std of residuals\n",
    "    \"\"\"\n",
    "    age = X[:, 0].reshape(-1, 1)\n",
    "    hours = X[:, 9]\n",
    "\n",
    "    reg = LinearRegression()\n",
    "    reg.fit(age, hours)\n",
    "\n",
    "    pred = reg.predict(age)\n",
    "    residuals = hours - pred\n",
    "    std = np.std(residuals)\n",
    "\n",
    "    return reg.coef_[0], reg.intercept_, std\n",
    "\n",
    "\n",
    "# Estimate parameters using training data\n",
    "a_est, b_est, std_est = estimate_linear_relationship(X_train)\n",
    "\n",
    "def compute_log_likelihood_adult(value, mean, std):\n",
    "    return norm.logpdf(value, loc=mean, scale=std)\n",
    "\n",
    "def compute_all_log_likelihoods_adult(X):\n",
    "    \"\"\"\n",
    "    Compute log-likelihood of linear dependency between age (col 0) and hours-per-week (col 9)\n",
    "    \"\"\"\n",
    "    age = X[:, 0]\n",
    "    hours = X[:, 9]\n",
    "\n",
    "    pred_hours = a_est * age + b_est\n",
    "    ll = compute_log_likelihood_adult(hours, pred_hours, std_est)\n",
    "    return ll\n",
    "\n",
    "\n",
    "def compute_causal_edge_score_adult(CF: pd.DataFrame, X_test: np.ndarray) -> float:\n",
    "    CF_np = CF.to_numpy()\n",
    "    # Ensure both arrays have shape (n_samples, 10)\n",
    "    assert CF_np.shape[1] >= 10, \"CF input must contain at least 10 features.\"\n",
    "\n",
    "    ll_cf = compute_all_log_likelihoods_adult(CF_np)\n",
    "    ll_x = compute_all_log_likelihoods_adult(X_test)\n",
    "    return np.mean(ll_cf - ll_x)\n",
    "\n",
    "\n",
    "CF = counterfactuals\n",
    "X_test_subset = X_test[:len(CF)]\n",
    "\n",
    "score = compute_causal_edge_score_adult(CF, X_test_subset)\n",
    "print(\"Causal-Edge Score (Adult):\", score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dafb99b1-4b8e-4f9e-92d5-45d535d93e9e",
   "metadata": {},
   "source": [
    "### DPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65658f3a-66d7-4911-8e26-3404eff539a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DPS Score (Adult Data): 0.7902\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "feature_names = [\n",
    "    \"age\",             # 0\n",
    "    \"education\",       # 1 (categorical)\n",
    "    \"education-num\",   # 2\n",
    "    \"marital-status\",  # 3 (categorical)\n",
    "    \"relationship\",    # 4 (categorical)\n",
    "    \"race\",            # 5 (categorical)\n",
    "    \"gender\",          # 6 (categorical)\n",
    "    \"capital-gain\",    # 7\n",
    "    \"capital-loss\",    # 8\n",
    "    \"hours-per-week\"   # 9\n",
    "]\n",
    "\n",
    "train_df = pd.DataFrame(X_train, columns=feature_names)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "CF.columns = feature_names  # Ensure proper alignment\n",
    "dependencies = {\n",
    "    'hours-per-week': ['age']\n",
    "}\n",
    "\n",
    "\n",
    "models = {}\n",
    "for target, parents in dependencies.items():\n",
    "    X = train_df[parents]\n",
    "    y = train_df[target]\n",
    "\n",
    "    model = LinearRegression()\n",
    "    model.fit(X, y)\n",
    "    models[target] = model\n",
    "\n",
    "\n",
    "errors = []\n",
    "for target, parents in dependencies.items():\n",
    "    X_cf = CF[parents]\n",
    "    y_cf_true = CF[target]\n",
    "    y_cf_pred = models[target].predict(X_cf)\n",
    "\n",
    "    std = train_df[target].std()\n",
    "    normalized_error = np.abs(y_cf_pred - y_cf_true) / std\n",
    "\n",
    "    scores = np.exp(-normalized_error)  # Higher = better preservation\n",
    "    errors.append(scores)\n",
    "\n",
    "\n",
    "DPS_scores = np.mean(np.stack(errors, axis=1), axis=1)\n",
    "DPS = np.mean(DPS_scores)\n",
    "\n",
    "print(f\"DPS Score (Adult Data): {DPS:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1fe271-0e70-4483-9804-7ba22abc4369",
   "metadata": {},
   "source": [
    "### IM1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6201dd25-4573-4864-b60c-391796901d50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74/74 [==============================] - 0s 459us/step\n",
      "74/74 [==============================] - 0s 495us/step\n"
     ]
    }
   ],
   "source": [
    "autoencoder_1 = load_model('AE1.h5')\n",
    "autoencoder_0 = load_model('AE0.h5')\n",
    "\n",
    "cf_samples = CF.values\n",
    "\n",
    "\n",
    "original_labels = np.argmax(clf.predict(X_test), axis=1)\n",
    "counterfactual_labels = np.argmax(clf.predict(cf_samples), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "87d3dd3e-5ca1-4d51-804e-8dd6d75e56b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IM1 Score: 0.8832\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.losses import MeanSquaredError, CategoricalCrossentropy\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Config\n",
    "continuous_indices = [0, 2, 7, 8, 9]\n",
    "categorical_indices = [1, 3, 4, 5, 6]\n",
    "n_categories = {\n",
    "    1: data['education'].nunique(),\n",
    "    3: data['marital-status'].nunique(),\n",
    "    4: data['relationship'].nunique(),\n",
    "    5: data['race'].nunique(),\n",
    "    6: data['gender'].nunique()\n",
    "}\n",
    "\n",
    "mse = MeanSquaredError()\n",
    "cce = CategoricalCrossentropy()\n",
    "\n",
    "def compute_reconstruction_loss(x, model):\n",
    "    \"\"\"\n",
    "    Compute mixed (continuous + categorical) reconstruction loss for a single sample.\n",
    "    \"\"\"\n",
    "    x = x.reshape(1, -1)\n",
    "    preds = model.predict(x, verbose=0)\n",
    "\n",
    "    loss_total = 0.0\n",
    "    for i, output in enumerate(preds):\n",
    "        if i in continuous_indices:\n",
    "            # MSE between original and predicted continuous value\n",
    "            loss = mse(x[:, i].reshape(-1, 1), output).numpy()\n",
    "        elif i in categorical_indices:\n",
    "            # Categorical crossentropy between one-hot and softmax output\n",
    "            true_cat = to_categorical(x[:, i].astype(int), num_classes=n_categories[i])\n",
    "            loss = cce(true_cat, output).numpy()\n",
    "        else:\n",
    "            raise ValueError(f\"Unexpected index {i} in reconstruction\")\n",
    "        loss_total += loss\n",
    "\n",
    "    return loss_total\n",
    "\n",
    "\n",
    "reconstruction_ratios = []\n",
    "\n",
    "for i in range(len(cf_samples)):\n",
    "    x_cf = cf_samples[i]\n",
    "    y_orig = original_labels[i]\n",
    "    y_cf = counterfactual_labels[i]\n",
    "\n",
    "    # Select appropriate AEs\n",
    "    if y_orig == 0 and y_cf == 1:\n",
    "        AE_o = autoencoder_0\n",
    "        AE_t = autoencoder_1\n",
    "    elif y_orig == 1 and y_cf == 0:\n",
    "        AE_o = autoencoder_1\n",
    "        AE_t = autoencoder_0\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "    # Compute reconstruction losses\n",
    "    loss_t = compute_reconstruction_loss(x_cf, AE_t)\n",
    "    loss_o = compute_reconstruction_loss(x_cf, AE_o)\n",
    "\n",
    "    if loss_o > 0:\n",
    "        reconstruction_ratios.append(loss_t / loss_o)\n",
    "\n",
    "# Final IM1 Score\n",
    "if reconstruction_ratios:\n",
    "    im1_score = np.mean(reconstruction_ratios)\n",
    "    print(f\"IM1 Score: {im1_score:.4f}\")\n",
    "else:\n",
    "    print(\"No valid counterfactuals to evaluate IM1.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d043f4f7-d5be-4e60-91d1-fc17ec1e8297",
   "metadata": {},
   "source": [
    "### Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af5ecbfe-4b49-4c3c-881c-cf978c850588",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def compute_mean_normalized_l2_distance(factuals, counterfactuals, feature_types, data):\n",
    "    \"\"\"\n",
    "    Compute the mean L2-normalized distance between factual and counterfactual samples,\n",
    "    normalizing each continuous feature by its (max - min) computed from the full data.\n",
    "\n",
    "    Parameters:\n",
    "    - factuals: np.ndarray of shape (n_samples, n_features)\n",
    "    - counterfactuals: np.ndarray of same shape\n",
    "    - feature_types: list of 'continuous' or 'categorical'\n",
    "    - data: np.ndarray of shape (n_data_samples, n_features) used to estimate feature ranges\n",
    "\n",
    "    Returns:\n",
    "    - mean_normalized_distance: float\n",
    "    \"\"\"\n",
    "    assert factuals.shape == counterfactuals.shape, \"Shape mismatch between factuals and counterfactuals\"\n",
    "    assert factuals.shape[1] == len(feature_types), \"Feature types length mismatch\"\n",
    "    assert data.shape[1] == factuals.shape[1], \"Data and factuals must have same number of features\"\n",
    "\n",
    "    n_samples, n_features = factuals.shape\n",
    "\n",
    "    # Compute feature ranges from the entire dataset\n",
    "    feature_ranges = []\n",
    "    for j in range(n_features):\n",
    "        if feature_types[j] == 'continuous':\n",
    "            max_val = np.max(data[:, j])\n",
    "            min_val = np.min(data[:, j])\n",
    "            range_val = max_val - min_val\n",
    "            feature_ranges.append(range_val if range_val != 0 else 1e-8)  # avoid division by zero\n",
    "        else:\n",
    "            feature_ranges.append(1.0)  # categorical features are treated as 0/1\n",
    "\n",
    "    distances = []\n",
    "\n",
    "    for i in range(n_samples):\n",
    "        dist_sq = 0\n",
    "        for j in range(n_features):\n",
    "            f, cf = factuals[i, j], counterfactuals[i, j]\n",
    "            if feature_types[j] == 'continuous':\n",
    "                norm_diff = (f - cf) / feature_ranges[j]\n",
    "                dist_sq += norm_diff ** 2\n",
    "            elif feature_types[j] == 'categorical':\n",
    "                dist_sq += 0 if f == cf else 1  # Categorical mismatch adds 1\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown feature type: {feature_types[j]}\")\n",
    "        distances.append(np.sqrt(dist_sq))  # L2 distance for the sample\n",
    "\n",
    "    return np.mean(distances)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d50ba8c3-9867-4827-b29a-a11c66e16b65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean L2 Distance: 2.3088702012963154\n"
     ]
    }
   ],
   "source": [
    "# Compute distance\n",
    "feature_types = ['continuous', 'categorical', 'continuous', 'categorical', 'categorical', 'categorical', 'categorical', 'continuous', 'continuous', 'continuous']\n",
    "data = np.vstack([X_train, X_test])\n",
    "\n",
    "mean_dist = compute_mean_normalized_l2_distance(X_test, cf_samples, feature_types, data)\n",
    "print(\"Mean L2 Distance:\", mean_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3b09cb-cad7-42b3-b7ba-a6b676da17b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930503a4-3bc8-4928-b952-17fa42b60a3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8619c1cb-1c03-4e47-95e0-0144efcbab45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9739e5-546a-4c6f-be2f-001856ced8ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472f97f1-4c53-470a-b0cc-6caf40ecbaf3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow-gpu-2.15.0",
   "language": "python",
   "name": "tensorflow-gpu-2.15.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
